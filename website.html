
<!DOCTYPE html>
<!-- Template by freewebsitetemplates.com -->
<html>
<head>
<meta charset="utf-8" />
<title>Intelligent Systems Lab</title>
<link rel="stylesheet" type="text/css" href="../style.css" media="all" />
</head>
<body>
	<div id="header">
			<div id="logo">
				<a href="../index.html"><img src="../images/lablogo.jpg" alt="" /></a>		
			</div>		
			<ul>
				<li><a href="../index.html"><span>home</span></a></li>
				<li><a href="../people_zw.html"><span>People</span></a></li>
				<li class="selected"><a href="../research_zw.html"><span>Research</span></a></li>
				<li ><a href="../database_zw.html"><span>Database</span></a></li>
				<li ><a href="href="http://www.ecse.rpi.edu/homepages/qji/publications.html"><span>Publications</span></a></li>
				<li><a href="http://www.ecse.rpi.edu/homepages/cvrl/Demo/demo1.htm"><span>Demos</span></a></li>
				<li><a href="../course_zw.html"><span>Courses</span></a></li>
                <li><a href="../code_zw.html.pdf"><span>code</span></a></li>
				<li><a href="../contact_zw.html"><span>contact us</span></a></li>					
			</ul>
	</div>
	<div id="body">
		<div class="about">
			<h1>3D Face Modeling and Reconstruction</h1>
				<p> 
				3D Face modeling is an active research area in computer vision, with an increasing attention in various applications such as 3D animation, AR/VR, human-computer interaction, etc. 
				Generally a 3D face shape can be modelled by the 3D morphable model (3DMM), which is a statistic model consisting of parameterized 3D shapes. Typically, a geometric 3DMM divides 
				the space of a 3D facial shape into an identity dimension and an expression dimension, which are spanned by identity bases and expression bases respectively. The geometric bases 
				are usually constructed from large scale 3D human facial scans. </p>
				<center>
				<br>
				<img src="/Users/chenyi/Dropbox/Mac/Documents/website/figures/3DMM.png" width=1000/> 
				<br>
				<p>
				Figure 1. 3D face shape bases and expression bases.
				</p>
				</center>
				<br>
				<br>
			<h2>1. 3D Face reconstruction from image</h2>
				<p>
				The problem of monocular image-based 3D face reconstruction can be solved by constructing the correspondency between image pixels and 3D face vertices through a weak perspective camera projection.
				Recovering the 3D face from image includes the shape & expression coefficients, pose and camera parameters. Sparse correspondence such as facial landmarks can be utilized to performe a coarse 3DMM 
				fitting as initialization and dense correspondence can be constructed based on texture rendering. 
				
				 </p>
				 
				<p> </p>
				
				<center>
				<br>
				<img src="/Users/chenyi/Dropbox/Mac/Documents/website/figures/au-blendshape.png" width=1000/> 
				<br>
				<p>
				Figure 2. 3D AU modeling on face expression bases.  
				</p>
				</center>

				
				<p> In the second work [5], we propose
				a hierarchical probabilistic model to capture the large shape variations due to expressions and head poses. Through the model, we could infer the
				true locations of facial features given the image measurements
				even if the face is with significant facial expression
				and pose (Figure 2). The hierarchical model implicitly captures the
				lower level shape variations of facial components using the
				mixture model. Furthermore, in the higher level, it also
				learns the joint relationship among facial components, the
				facial expression, and the pose information through automatic
				structure learning and parameter estimation of the
				probabilistic model (nodes in the dotted rectangular in Figure 2). Experimental results on benchmark
				databases demonstrate the effectiveness of the proposed hierarchical
				probabilistic model. </p>
				
				<center>
				<br>
				<img src="Hierarhical.png" width=600/> 
				<br>
				</center>
				<p>
				Figure 3. (a) The hierarchical probabilistic model for facial landmark detection under varying facial expressions and head poses. Nodes on the first (bottom) layer represent the measurements of facial landmark locations from the local point detectors. Nodes on the second layer represent the ground truth facial landmark locations we want to infer. Nodes on the third layer are discrete hidden nodes representing the states of different facial components (e.g., mouth open and closed). Nodes on the top layer represent the facial expression and head pose labels. Nodes on the lower three layers captures the local shape variations, while nodes on the top two layers capture the global relationships. (b) Experimental results on benchmark databases (e.g., CK+, MMI, FERET and AFLW).
				</p>
				
				
				
				<p>In the third work [6-7],
				to capture the large facial shape variations due to expressions and head poses, we proposed a discriminative deep
				face shape model that is constructed based on an augmented
				factorized three-way Restricted Boltzmann Machines model (Figure 3).
				Specifically, the discriminative deep model combines the top-down information
				from the embedded face shape patterns and
				the bottom up measurements from local point detectors in a
				unified framework. In addition, it implicitly decouples the face shapes into expression-related parts and
				pose-related parts with the help of additional frontal face shapes. Along with the model, effective
				algorithms are proposed to perform model learning and
				to infer the true facial point locations from their measurements.
				Based on the discriminative deep face shape model,
				68 facial points are detected on facial images in both controlled
				and ''in-the-wild'' conditions. Experiments on benchmark
				data sets show the effectiveness of the proposed facial
				point detection algorithm against state-of-the-art methods.</p>
			
		
				<center>
				<br>
				<img src="RBM_shape.png" width=600/> 
				<br>
				</center>
				<p>
				Figure 4. (a) The proposed discriminative deep face shape model. It consists of a factorized three-way RBM connecting the arbitrary facial shape (x), the corresponding frontal facial shape (y), and the hidden nodes (h1). It also includes two RBMs that model the connections among the arbitrary facial shape (x), the hidden nodes (h2), and the measurements of the arbitrary facial shape (m). (b) Arbitrary facial shape and its corresponding frontal facial shape for the same subject and expression. (c) Experimental results on benchmark databases (e.g., MultiPIE, Helen, LFPW and AFW). 
				</p>
				<br>
				<br>
			
			<h2>2. 3D AU modeling as face blendshapes. </h2>		
				<p>
				There have been tremendous improvements for 3D facial geometry recovery. However,
				it is still challenging to reconstruct subtle facial motions or expressions in 3D space. In fact, the existing algorithms
				usually can only handle one of them. In this work [8-9], we propose
				a unified robust cascade regression framework that can
				handle both images with severe occlusion and images with
				large head poses (Figure 4). Specifically, the method iteratively predicts
				the landmark occlusions and the landmark locations.
				For occlusion estimation, instead of directly predicting the
				binary occlusion vectors, we introduce a supervised regression
				method that gradually updates the landmark visibility
				probabilities in each iteration to achieve robustness. In addition,
				we explicitly add occlusion pattern as a constraint to
				improve the performance of occlusion prediction. For landmark
				detection, we combine the landmark visibility probabilities,
				the local appearances, and the local shapes to iteratively
				update their positions. The experimental results
				show that the proposed method is significantly better than
				state-of-the-art works on images with severe occlusion and
				images with large head poses. It is also comparable to other
				methods on general ''in-the-wild'' images. </p>
				
				<center>
				<br>
				<img src="/Users/chenyi/Dropbox/Mac/Documents/website/figures/au-blendshape.png" width=1000/> 
				<br>
				</center>
				<p>
				Figure 5. 3D AU-based blendshapes and deformation maps.   
				</p>
				<br>
				<br>

		    <h2>3. Joint facial landmark detection and action unit recognition</h2>
							
				<p>
				Facial action unit recognition and facial landmark detection
				are two related tasks for face analysis. But, they are seldomly exploited together. In this work [10], we improve upon the cascade regression
				framework and propose the Constrained Joint Cascade
				Regression Framework (CJCRF) for simultaneous facial
				action unit recognition and facial landmark detection (Figure 5). In particular, we first learn the relationships
				among facial action units and face shapes as a constraint.
				Then, in the proposed constrained joint cascade
				regression framework, with the help from the constraint, we
				iteratively update the facial landmark locations and the action
				unit activation probabilities until convergence. Experimental
				results demonstrate that the intertwined relationships
				of facial action units and face shapes boost the performances
				of both facial action unit recognition and facial
				landmark detection. The experimental results also demonstrate
				the effectiveness of the proposed method comparing
				to the state-of-the-art works. </p>
				
				<center>
				<br>
				<img src="AU_landmark.png" width=500/> 
				<br>
				<p>
				Figure 6. Joint facial landmark detection and action unit recognition.  
				</p>
				</center>
				<br>
				<br>
			
				
				<h2>Publications</h2>
				<ul>
				<li>
				<p> [1] Yan Tong, Yang Wang, Zhiwei Zhu, and Qiang Ji, ''Robust Facial Feature Tracking under Varying Face Pose and Facial Expression,'' Pattern Recognition, Vol. 40, No. 11, pp. 3195-3208, November 2007. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Tong2007a.pdf" target="_blank">PDF</a> </p>
				</li>

				<li>
				<p> [2] Zhiwei Zhu and Qiang Ji, ''Robust Pose Invariant Facial Feature Detection and Tracking in Real-Time,'' the 18th International Conference on Pattern Recognition (ICPR), Hongkong, August, 2006. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Zhu2006a.pdf" target="_blank">PDF</a>  </p>
				</li>
				
				<li>
				<p> [3] Yan Tong, Yang Wang, Zhiwei Zhu, and Qiang Ji, ''Facial Feature Tracking using a Multi-State Hierarchical Shape Model under Varying Face Pose and Facial Expression,'' the 18th International Conference on Pattern Recognition (ICPR), Hongkong, August, 2006.  <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Tong2006a.pdf" target="_blank">PDF</a> </p>
				</li>
				
				<li>
				<p> [4] Yan Tong and Qiang Ji, ''Multiview Facial Feature Tracking with a Multi-modal Probabilistic Model,'' the 18th International Conference on Pattern Recognition (ICPR), Hongkong, August, 2006. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Tong2006b.pdf" target="_blank">PDF</a> </p>
				</li>
				
				<li>
				<p> [5] Yue Wu, Ziheng Wang, and Qiang Ji, ''A Hierarchical Probabilistic Model for Facial Feature Detection,'' IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Wu2014c.pdf" target="_blank">PDF</a>  </p>
				</li>
	
				<li>
				<p> [6] Yue Wu, Zuoguan Wang, and Qiang Ji, ''Facial Feature Tracking under Varying Facial Expressions and Face Poses based on Restricted Boltzmann Machines,'' IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Wu2013c.pdf" target="_blank">PDF</a>  </p>
				</li>

				<li>
				<p> [7] Yue Wu and Qiang Ji, ''Discriminative Deep Face Shape Model for Facial Point Detection,'' International Journal of Computer Vision (IJCV), Vol. 113, Issue 1, pp 37-53, May 2015. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Wu2014.pdf" target="_blank">PDF</a>  </p>
				</li>

				<li>
				<p> [8] Yue Wu and Qiang Ji, ''Robust Facial Landmark Detection under Significant Head Poses and Occlusion,'' International Conference on Computer Vision (ICCV), 2015. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Wu2015b.pdf" target="_blank">PDF</a>  </p>
				</li>
				<li>
				<p> [9] Yue Wu and Qiang Ji, ''Shape Augmented Regression Method for Face Alignment,'' 300 Videos in the Wild (300-VW) Challenge and Workshop, International Conference on Computer Vision Workshop(ICCVW), 2015.   </p>
				</li>
				<li>
				<p> [10] Yue Wu and Qiang Ji, ''Constrained Joint Cascade Regression Framework for Simultaneous Facial Action Unit Recognition and Facial Landmark Detection,'' IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. <a href="https://www.ecse.rpi.edu/~cvrl/Publication/pdf/Wu2016a.pdf" target="_blank">PDF</a>  </p>
				</li>
				</ul>

				<h2>Demos</h2>
				<ul>
				<li> Recent demos: <a href="https://www.ecse.rpi.edu/homepages/cvrl/Demo/demo1.htm" target="_blank">go to this link. </a> 
				</li>
				<li> Previous demos:  <a href="http://www.ecse.rpi.edu/~cvrl/zhiwei/featuretracking/facialfeature_MPEG4.avi">Real-time facial Feature tracking demo</a> 
				</li>
				<li> Previous demos:  <a href="http://www.ecse.rpi.edu/homepages/cvrl/Demo/demo_facial_feature2.avi">Real time facial feature tracking under large pose and scale changes</a> 
				</li>
				</ul>
			</div>
		</div>
	</div>

	<div id="footer">
		<div>
			<p>&copy Copyright 2012. All rights reserved</p>
		</div>
	</div>
</body>
</html>